name: CI

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  lint-and-format:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install pre-commit
        run: pip install pre-commit

      - name: Install pre-commit hooks
        run: pre-commit install-hooks

      - name: Run pre-commit
        run: pre-commit run --all-files

      - name: Run Ruff linting
        run: |
          pip install ruff
          ruff check .

      - name: Check formatting with Ruff
        run: ruff format --check .

  type-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Type check with mypy
        run: mypy chronicle_mcp/

  codespell:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run codespell
        uses: codespell-project/actions-codespell@v2
        with:
          skip: ".git,*.svg,*.png,*.md"
          ignore_words_list: "and,param,be,to,the"

  test:
    needs: [lint-and-format, type-check]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run pytest with coverage
        run: pytest --cov=chronicle_mcp --cov-report=xml --cov-report=term-missing

      - name: Upload coverage to Codecov
        if: matrix.python-version == '3.11'
        uses: codecov/codecov-action@v4
        with:
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  cross-platform-test:
    needs: test
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.11"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run tests
        run: pytest tests/ -v

  benchmark:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'run-benchmark')
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run benchmark tests
        run: |
          pytest tests/ -v --benchmark-only --benchmark-json=benchmark.json || true

      - name: Process benchmark results
        if: hashFiles('benchmark.json') != ''
        run: |
          if [ -f benchmark.json ] && [ -s benchmark.json ]; then
            if python -c "import json; json.load(open('benchmark.json'))" 2>/dev/null; then
              echo "has_results=true" >> $GITHUB_ENV
            else
              rm -f benchmark.json
              echo "has_results=false" >> $GITHUB_ENV
            fi
          else
            echo "has_results=false" >> $GITHUB_ENV
          fi

      - name: Display benchmark results
        if: env.has_results == 'true'
        run: |
          echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "View full results at: https://nikolasil.github.io/chronicle-mcp/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          python -c "import json; d=json.load(open('benchmark.json')); print(json.dumps({'testsuites': d.get('testsuites', [])[:3]}, indent=2))" >> $GITHUB_STEP_SUMMARY || true
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        if: env.has_results == 'true' && github.ref == 'refs/heads/main'
        with:
          name: Python Benchmark
          tool: pytest
          output-file-path: benchmark.json
          save-data-file: true
          comment-on-alert: true
          summary-always: true
          auto-push: true
          gh-pages-branch: gh-pages
          github-token: ${{ secrets.GITHUB_TOKEN }}
